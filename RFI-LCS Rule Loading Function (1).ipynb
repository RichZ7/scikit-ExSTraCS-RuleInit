{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f5ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with inputted rules\n",
      "0.503125\n",
      "Score with LCS after initialization with rules and learning iterations\n",
      "0.80125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from skExSTraCS import ExSTraCS\n",
    "from skExSTraCS import Classifier\n",
    "from skExSTraCS import OfflineEnvironment\n",
    "\n",
    "data = pd.read_csv('C://Users//Dasar//Downloads//a_20s_1600her_0.4__maf_0.2_EDM-2_01.txt', delim_whitespace=True)\n",
    "all_rules_csv = pd.read_csv('C://Users//Dasar//Downloads//rules_v2.csv')\n",
    "rule_csv  = all_rules_csv.sample(n=100, random_state=1)\n",
    "pickle_file = \"C://Users//Dasar//Downloads//pickle_output.txt\"\n",
    "\n",
    "def RFILCS_Rule_Loading (data, rule_csv, pickle_file, classLabel, number_of_iterations):\n",
    "    rule_count = rule_csv.shape[0]\n",
    "    instance_count = data.shape[0]\n",
    "    attribute_list = []\n",
    "    for col in data.columns:\n",
    "        attribute_list.append(col)\n",
    "        \n",
    "    rule_accuracy_dict = {}\n",
    "\n",
    "    for rule in range (0, rule_count):\n",
    "        match_set = []\n",
    "        correct_set = []\n",
    "        for instance in range (0, instance_count):\n",
    "            match = True\n",
    "            attribute_index_string = rule_csv.iloc[rule]['Attribute Index']\n",
    "            attribute_index_list = ast.literal_eval(attribute_index_string)\n",
    "            condition_string = rule_csv.iloc[rule]['Condition']\n",
    "            condition_list = ast.literal_eval(condition_string)\n",
    "        \n",
    "            for i in range(0, len(attribute_index_list)):\n",
    "                if data.iloc[instance][attribute_list[attribute_index_list[i]]] not in condition_list[i]:\n",
    "                    match = False\n",
    "            \n",
    "            if match == True:\n",
    "                match_set.append(instance)\n",
    "        \n",
    "            if match == True and data.iloc[instance]['Class'] == rule_csv.iloc[rule]['Class']:\n",
    "                correct_set.append(instance)\n",
    "    \n",
    "        if len(match_set) > 0:\n",
    "            rule_accuracy_dict[rule] = len(correct_set) / len(match_set)\n",
    "        elif len(match_set) == 0:\n",
    "            rule_accuracy_dict[rule] = 0\n",
    "    \n",
    "    newPopSet = []\n",
    "\n",
    "    for rule in range (0, rule_count):\n",
    "        dummymodel = ExSTraCS()\n",
    "        newClassifier  = Classifier(dummymodel)\n",
    "        attribute_index_string = rule_csv.iloc[rule]['Attribute Index']\n",
    "        attribute_index_list = ast.literal_eval(attribute_index_string)\n",
    "        newClassifier.specifiedAttList = attribute_index_list\n",
    "    \n",
    "        condition_string = rule_csv.iloc[rule]['Condition']\n",
    "        condition_list = ast.literal_eval(condition_string)\n",
    "        newClassifier.condition = condition_list\n",
    "    \n",
    "        newClassifier.phenotype = rule_csv.iloc[rule]['Class']\n",
    "        newClassifier.fitness = rule_accuracy_dict[rule]\n",
    "        newClassifier.accuracy = rule_accuracy_dict[rule]\n",
    "        newClassifier.numerosity = rule_csv.iloc[rule]['Numerosity']\n",
    "    \n",
    "        newClassifier.aveMatchSetSize = 1\n",
    "        newClassifier.timeStampGA = 0\n",
    "        newClassifier.initTimeStamp = 0\n",
    "    \n",
    "        newPopSet.append(newClassifier)\n",
    "\n",
    "    \n",
    "    dataFeatures = data.drop(classLabel,axis = 1).values\n",
    "    dataPhenotypes = data[classLabel].values\n",
    "    env = OfflineEnvironment(dataFeatures, dataPhenotypes, dummymodel)    \n",
    "\n",
    "    dummymodel = ExSTraCS()\n",
    "    dummymodel.env = OfflineEnvironment(dataFeatures, dataPhenotypes, dummymodel) \n",
    "    dummymodel.hasTrained = True\n",
    "    dummymodel.iterationCount = dummymodel.learning_iterations\n",
    "    dummymodel.finalMetrics = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, env, newPopSet, newPopSet]\n",
    "    dummymodel.pickle_model(pickle_file)\n",
    "\n",
    "\n",
    "\n",
    "    model2 = ExSTraCS(learning_iterations = number_of_iterations,nu=10,N=2000,reboot_filename=pickle_file)\n",
    "    print(\"Score with inputted rules\")\n",
    "    print(model2.score(dataFeatures,dataPhenotypes))\n",
    "    model2.fit(dataFeatures,dataPhenotypes)\n",
    "    print(\"Score with LCS after initialization with rules and learning iterations\")\n",
    "    print(model2.score(dataFeatures,dataPhenotypes))\n",
    "\n",
    "RFILCS_Rule_Loading (data, rule_csv, 'C://Users//Dasar//Downloads//rules_v2.csv', 'Class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763c78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
